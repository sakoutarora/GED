{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom nltk.tokenize import RegexpTokenizer\nfrom torch.nn.utils.rnn import pad_sequence\ntpath = '../input/VT-data/train_data.csv'\n\n\nclass Vocab:\n    def __init__(self):\n        self.stoi = dict()\n        self.itos = dict()\n        self.tokenizer = RegexpTokenizer('[a-zA-z]+')\n        self.stoi['<PAD>'] = 0\n        self.stoi['<EOS>'] = 1\n        self.stoi['<SOS>'] = 2\n        self.stoi['<UNK>'] = 3\n        self.itos[0] = '<PAD>'\n        self.itos[1] = '<EOS>'\n        self.itos[2] = '<SOS>'\n        self.itos[3] = '<UNK>'\n        self.counter = 4\n\n    def create_vocab(self, alldata):\n        for lines in alldata:\n            lin = self.tokenizer.tokenize(lines)\n            for word in lin:\n                if word not in self.stoi:\n                    self.stoi[word.lower()] = self.counter\n                    self.itos[self.counter] = word.lower()\n                    self.counter = self.counter + 1\n\n\nclass DataGen(Dataset):\n    def __init__(self, path, train_path = tpath):\n        super(DataGen, self).__init__()\n        self.data = pd.read_csv(path)\n        self.vocab = Vocab()\n        self.vocab.create_vocab(pd.read_csv(train_path).input.values)\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, item):\n        line = self.data.iloc[item]['input']\n        lab = self.data.iloc[item]['labels']\n        word = self.vocab.tokenizer.tokenize(line)\n        word = [ self.vocab.stoi[wd.lower()] if wd.lower() in self.vocab.stoi else self.vocab.stoi['<UNK>'] for wd in word ]\n        word.append(self.vocab.stoi['<EOS>'])\n        word = [self.vocab.stoi['<SOS>']] + word\n        return torch.Tensor(word), torch.Tensor([lab])\n\n\nclass MyCollate:\n    def __init__(self, pad_idx):\n        self.pad_idx = pad_idx\n\n    def __call__(self, batch):\n        wor = [item[1] for item in batch]\n        wor = torch.cat(wor, dim=0)\n        target = [item[0] for item in batch]\n        target = pad_sequence(target, batch_first=True, padding_value=self.pad_idx)\n        return wor, target","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-09T08:41:35.985436Z","iopub.execute_input":"2022-04-09T08:41:35.985691Z","iopub.status.idle":"2022-04-09T08:41:36.001631Z","shell.execute_reply.started":"2022-04-09T08:41:35.985661Z","shell.execute_reply":"2022-04-09T08:41:36.000662Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"tpath = '../input/VT-data/train_data.csv'\ncpath = '../input/VT-data/val_data.csv'","metadata":{"execution":{"iopub.status.busy":"2022-04-09T08:41:37.115453Z","iopub.execute_input":"2022-04-09T08:41:37.116054Z","iopub.status.idle":"2022-04-09T08:41:37.120705Z","shell.execute_reply.started":"2022-04-09T08:41:37.116015Z","shell.execute_reply":"2022-04-09T08:41:37.119984Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass Gramodel(nn.Module):\n    def __init__(self, num_embeds, embed_dim):\n        super(Gramodel, self).__init__()\n        self.embed = nn.Embedding(num_embeddings=num_embeds, embedding_dim=embed_dim)\n        self.LSTM = nn.LSTM(input_size=embed_dim, hidden_size=embed_dim, num_layers=1, bidirectional=True,\n                            batch_first=True)\n        self.lin = nn.Sequential(nn.Linear(2*embed_dim, 64),\n                                 nn.ReLU(),\n                                 nn.Linear(64, 2),\n                                 nn.Softmax(dim=1))\n        self.drop = nn.Dropout(p=0.4)\n\n    def forward(self, x):\n        emb = self.embed(x.long())\n        self.drop(emb)\n        output, (hn, cn) = self.LSTM(emb)\n        output = self.drop(output)\n        output = self.lin(output[:, -1, :].squeeze(1))\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:24:54.912787Z","iopub.execute_input":"2022-04-09T09:24:54.913633Z","iopub.status.idle":"2022-04-09T09:24:54.922662Z","shell.execute_reply.started":"2022-04-09T09:24:54.913588Z","shell.execute_reply":"2022-04-09T09:24:54.921890Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import f1_score \nfrom sklearn.metrics import classification_report\n\ndef accuracy(model, loader):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    model.eval()\n    num_correct = 0\n    num_samples = 0\n    preds = []\n    labels = []\n    with torch.no_grad():\n        for label, data in tqdm(loader):\n            label = label.to(device)\n            data = data.to(device, dtype = torch.float)\n            pre = model(data)\n            _, pre = torch.max(pre, dim=1)\n            num_correct += (pre == label).sum()\n            num_samples += pre.size(0)\n            preds = preds + pre.tolist()\n            labels = labels + label.tolist()\n    \n    report = classification_report(labels, preds, output_dict=True)\n    f1 = report['macro avg']['f1-score']        \n    return (float(num_correct)/float(num_samples), f1)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:24:55.424193Z","iopub.execute_input":"2022-04-09T09:24:55.424449Z","iopub.status.idle":"2022-04-09T09:24:55.433221Z","shell.execute_reply.started":"2022-04-09T09:24:55.424421Z","shell.execute_reply":"2022-04-09T09:24:55.432388Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\n\ndef train():\n    vc = DataGen(path=tpath)  \n    pad = vc.vocab.stoi['<PAD>']\n    dataload = DataLoader(vc, batch_size=128, shuffle=True, collate_fn=MyCollate(pad_idx=pad))\n    \n    vcv = DataGen(path=cpath)  \n    pad = vc.vocab.stoi['<PAD>']\n    dataloadcv = DataLoader(vcv, batch_size=128, shuffle=True, collate_fn=MyCollate(pad_idx=pad))\n    \n    lent = vc.vocab.counter\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    mod = Gramodel(num_embeds=lent,embed_dim= 256).to(device)\n    crit = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(params=mod.parameters(), lr=3e-4)\n    epochs = 70\n    maxvalf1 = 0.4\n    mod.train()\n    for epoch in range(epochs):\n        print('EPOCH {}'.format(epoch))\n        losses = 0\n        for label, data in tqdm(dataload):\n            label = label.to(device)\n            data = data.to(device)\n            prediction = mod(data)\n            loss = crit(prediction, label.long())\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            losses += loss\n        \n        reportv = accuracy(mod, dataloadcv)\n        valf1 = reportv[1]\n        if valf1 > maxvalf1:\n            print('---------------Saving CheckPOINT---------------')\n            path = 'chechpoint' + str(epoch) + '.pth' \n            torch.save(mod.state_dict(), path)  \n            maxvalf1 = valf1\n            \n        reportt = accuracy(mod, dataload)\n        \n        print('Train Loss {}'.format(losses/len(dataload.dataset)) )\n        print(\"Train Accu {}  F1 {} \".format(reportt[0], reportt[1]))\n        print(\"Val Accu {}  F1 {} \".format(reportv[0], reportv[1]))\n        mod.train()\n    return mod","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:40:12.028847Z","iopub.execute_input":"2022-04-09T09:40:12.029130Z","iopub.status.idle":"2022-04-09T09:40:12.044885Z","shell.execute_reply.started":"2022-04-09T09:40:12.029095Z","shell.execute_reply":"2022-04-09T09:40:12.043991Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"model = train()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:40:12.537516Z","iopub.execute_input":"2022-04-09T09:40:12.537969Z","iopub.status.idle":"2022-04-09T09:48:04.650099Z","shell.execute_reply.started":"2022-04-09T09:40:12.537932Z","shell.execute_reply":"2022-04-09T09:48:04.648688Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"model = Gramodel(num_embeds=lent, embed_dim=256)\nmodel.load_state_dict(torch.load('./chechpoint13.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:48:11.253251Z","iopub.execute_input":"2022-04-09T09:48:11.253521Z","iopub.status.idle":"2022-04-09T09:48:11.445682Z","shell.execute_reply.started":"2022-04-09T09:48:11.253490Z","shell.execute_reply":"2022-04-09T09:48:11.444891Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nnum_correct = []\nnum_samples = []\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nmodel.eval()\nwith torch.no_grad():\n    for label, data in tqdm(dataload):\n        label = label.to(device)\n        data = data.to(device, dtype = torch.float)\n        pre = model(data)\n        _, pre = torch.max(pre, dim=1)\n        num_correct += pre.tolist()\n        num_samples += label.tolist()\n\nreport = classification_report(num_samples, num_correct)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:48:20.361208Z","iopub.execute_input":"2022-04-09T09:48:20.361782Z","iopub.status.idle":"2022-04-09T09:48:26.733774Z","shell.execute_reply.started":"2022-04-09T09:48:20.361744Z","shell.execute_reply":"2022-04-09T09:48:26.733086Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"vcv = DataGen(path=cpath)  \npad = vc.vocab.stoi['<PAD>']\ndataloadcv = DataLoader(vc, batch_size=128, shuffle=True, collate_fn=MyCollate(pad_idx=pad))\n\nnum_correct = []\nnum_samples = []\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nmodel.eval()\nwith torch.no_grad():\n    for label, data in tqdm(dataloadcv):\n        label = label.to(device)\n        data = data.to(device, dtype = torch.float)\n        pre = model(data)\n        _, pre = torch.max(pre, dim=1)\n        num_correct += pre.tolist()\n        num_samples += label.tolist()\n\nreport = classification_report(num_samples, num_correct)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:48:26.736151Z","iopub.execute_input":"2022-04-09T09:48:26.736408Z","iopub.status.idle":"2022-04-09T09:48:33.088779Z","shell.execute_reply.started":"2022-04-09T09:48:26.736380Z","shell.execute_reply":"2022-04-09T09:48:33.088063Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"def prediction(mod, testpath, dataset):\n    test = pd.read_csv(testpath)\n    answer = []\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    mod.to(device)\n    mod.eval()\n    for idx in range(len(test)):\n        word = dataset.vocab.tokenizer.tokenize(test.iloc[idx]['input'])\n        word = [dataset.vocab.stoi[wd.lower()] for wd in word if wd.lower() in dataset.vocab.stoi]\n        word.append(dataset.vocab.stoi['<EOS>'])\n        word.append(dataset.vocab.stoi['<PAD>'])\n        word = [dataset.vocab.stoi['<SOS>']] + word\n        vector = torch.Tensor(word)\n        vector = vector.to(device)\n        with torch.no_grad():\n            pred = mod(vector.unsqueeze(0))\n            _, pre = pred.max(1)\n            answer.append(pre.item())\n    return answer\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:48:33.090451Z","iopub.execute_input":"2022-04-09T09:48:33.090717Z","iopub.status.idle":"2022-04-09T09:48:33.100909Z","shell.execute_reply.started":"2022-04-09T09:48:33.090679Z","shell.execute_reply":"2022-04-09T09:48:33.099557Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"ans = prediction(model, '../input/VT-data/test_data.csv', vc)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:49:04.755739Z","iopub.execute_input":"2022-04-09T09:49:04.756007Z","iopub.status.idle":"2022-04-09T09:49:15.784049Z","shell.execute_reply.started":"2022-04-09T09:49:04.755976Z","shell.execute_reply":"2022-04-09T09:49:15.783348Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"testpath = '../input/VT-data/test_data.csv'\ndf = pd.read_csv(testpath)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:49:19.854709Z","iopub.execute_input":"2022-04-09T09:49:19.854975Z","iopub.status.idle":"2022-04-09T09:49:19.870746Z","shell.execute_reply.started":"2022-04-09T09:49:19.854946Z","shell.execute_reply":"2022-04-09T09:49:19.870092Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"df['predicted_label'] = ans","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:49:21.191424Z","iopub.execute_input":"2022-04-09T09:49:21.191676Z","iopub.status.idle":"2022-04-09T09:49:21.199625Z","shell.execute_reply.started":"2022-04-09T09:49:21.191647Z","shell.execute_reply":"2022-04-09T09:49:21.198941Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:49:22.334941Z","iopub.execute_input":"2022-04-09T09:49:22.335495Z","iopub.status.idle":"2022-04-09T09:49:22.349756Z","shell.execute_reply.started":"2022-04-09T09:49:22.335455Z","shell.execute_reply":"2022-04-09T09:49:22.348862Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"df.loc[df['predicted_label'] == 1 ].iloc[140]['input']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-09T09:49:29.410551Z","iopub.execute_input":"2022-04-09T09:49:29.410805Z","iopub.status.idle":"2022-04-09T09:49:29.418669Z","shell.execute_reply.started":"2022-04-09T09:49:29.410776Z","shell.execute_reply":"2022-04-09T09:49:29.417771Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"df.to_csv('saksham_arora_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T09:49:59.356478Z","iopub.execute_input":"2022-04-09T09:49:59.356744Z","iopub.status.idle":"2022-04-09T09:49:59.401762Z","shell.execute_reply.started":"2022-04-09T09:49:59.356715Z","shell.execute_reply":"2022-04-09T09:49:59.401080Z"},"trusted":true},"execution_count":95,"outputs":[]}]}